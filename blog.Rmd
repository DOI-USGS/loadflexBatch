---
title: "Loadflex Batch Mode"
author: "David Watkins"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  md_document:
    variant: markdown_github
  pdf_document: null
slug: loadflex-batch
---
```{r setup, include=FALSE}
library(knitr)

knit_hooks$set(plot=function(x, options) {
  sprintf(
    "<img src='/%s%s-%d.%s'/>", 
    options$fig.path, options$label, options$fig.cur, options$fig.ext)
})

opts_chunk$set(
  echo=TRUE,
  fig.path="static/loadflex-batch/"
)
```

### Loadflex batch script

The script at https://github.com/USGS-R/loadflexBatch/blob/master/batch.R automates running multiple load models for multiple sites and consitutents, using the `loadflex` package along with some features of `rloadest`.  Output is collated across all sites for easy analysis of input data, predicted loads, and model metrics.  This post will go through basic setup and use of the script as it exists now.  In the future it may be hardened into a part of the actual `loadflex` package.    

## Installation and setup

First, go to the Github repository [USGS-R/loadflexBatch](https://github.com/USGS-R/loadflexBatch) and download the zip file (using the big green button) to your preferred directory for R projects, and unzip it. Open RStudio, start a new project (File -> New Project), select the "Existing directory" option. select the `loadflexBatch-master` folder, and click "Create Project". Note that on Windows there will be two `loadflexBatch-master` folders — select the lower-level one. You will now be inside the `loadflexBatch-master` folder, and have access to the batch script.
```{r} 
list.files()
```
  
Next, we need to install the packages that the script depends on.  In your console, run 
```{r eval = FALSE}
install.packages(
  c('dplyr', 'rloadest', 'devtools', 'yaml'), 
  repos = c('https://owi.usgs.gov/R', 'https://cloud.r-project.org'))
```

We will also install the main `loadflex` package, directly from Github to ensure we have the very latest version:
```{r eval=FALSE}
devtools::install_github("USGS-R/loadflex")
```
The most up-to-date installation instructions can always be found at [https://github.com/USGS-R/loadflex#installation](https://github.com/USGS-R/loadflex#installation).

Now we are ready to look at the user inputs, file structure, and run the script.

## Input parameters and directory setup

Open the main script, `batch.R`, by clicking on it in the 'Files' pane in the lower right of your RStudio window.  There is a basic description of the file at the top.  Below that are the user inputs, set up for the included example data.  The user supplies information about input/output folder names and locations, constituents, load units, and load rate units.  The constituent names need to match the names of the input subfolders that contain the input data (paired water quality and discharge measurements).  The discharge folder, containing the discharge measurements used to make the load predictions, works the same way. 

In addition to the User Inputs specified within `batch.R`, the file indicated by `siteInfo` should be a comma-separated (.csv) file (inside `inputFolder`) that contains metadata for individual water quality and discharge sites.  Look at the example file (`three_ANA_sites/input/siteInfo.csv`) for reference on the required column names and format:
```{r echo = FALSE}
read.csv('three_ANA_sites/input/siteInfo.csv')
```

For each row of the `siteInfo` file, the value in the `constituent` column should match both (1) a folder name given as a `constituent` or `dischargeFolder` in the User Inputs section of `batch.R`, and (2) an actual folder within the `inputFolder`. And then within each of those folders, there should be a separate data file (.csv format) for each site, with a file name equal to the names given in the `site.id` column of the `siteInfo` file.

For this example, the input folder structure is therefore:

```
- three_ANA_sites
  - input
    - siteInfo.csv
    - NO3
      - RONC02800.csv
      - MOGU02900.csv
      - ORIZ02800.csv
    - PT
      - RONC02800.csv
      - MOGU02900.csv
      - ORIZ02800.csv
    - Q
      - RONC02800.csv
      - MOGU02900.csv
      - ORIZ02800.csv
```

The batch script loops over the constituents listed in the User Inputs section, finds the corresponding rows in `siteInfo.csv`, and identifies the one concentration file and one discharge file for each site-constituent combination. Both files bear the name of a `site.id`, and they appear in a constituent folder (e.g., `NO3`) and the discharge folder (`Q`), respectively.

Here is an example of how the input consituent data should be formatted, with columns for date of the observation (`date`), discharge (`Q`), the concentration of the constituent (in this case `NO3`), additional columns that are ignored by this script (e.g., `CODIGO_ESTACAO`), and the censoring and data quality code (`status`), which follows the Brazillian ANA's convention of 0=bad value, 1=normal value, 2=value known to be less than or equal to the number given in the constituent (`NO3`) column.
```{r}
head(read.csv('three_ANA_sites/input/NO3/MOGU02900.csv'), 5)
```

And here is how the input discharge data should be formatted, with columns for date of the observation (`date`) and mean daily discharge (`Q`), plus optional additional columns that will be ignored by `batch.R`. Whereas the constituent data file only has rows for those dates on which concentration was measured, the discharge data file has rows for every date on which flux is to be estimated.
```{r}
head(read.csv('three_ANA_sites/input/Q/MOGU02900.csv'), 5)
```

## Running the script

Once the input parameters and files are set correctly, you can source the script.  It is configured to run with the included example data to start.
```{r eval = FALSE}
source('batch.R')
```

## Behind the scenes

The script reads, processes, and writes output for each site/consituent combination individually.  Currently, it runs three models for each iteration — the `rloadest` 5-parameter regression model, an interpolation model from `loadflex`, and a composite interpolation-regression model also from `loadflex`.  Additional models can be added with some modifications to the script.

If the drainage basin areas for paired water quality and discharge sites are different (in the site metadata file, e.g `siteInfo.csv`), discharge is scaled by the appropriate ratio.  The resulting estimates describe fluxes at the water quality monitoring site. The script matches up water quality and discharge sites by looking to the `matching.site` column of the `siteInfo` file. The `matching.site` ID should be the same for the constituent and discharge sites you wish to combine, even if the `site.id` differs for those two sites.

If a constituent dataset includes censored data (i.e., `status` flags of 2), those data are passed to the `loadReg2` model in the censored data format required by `rloadest`. The composite and interpolation models are then excluded, because these models are not equipped to handle censored data.

All the site metadata is stored in a `loadflex::metadata` R object, which is referenced throughout the script.

The script uses several built-in `loadflex` functions to create the outputs in R, which the script then writes to files. Those functions include `summarizeInputs`, `summarizeModel`, `predictSolute`, and `aggregateSolute`. Descriptions of these functions can be found by typing `?` followed by the function name at the R prompt.

## Output

Like the input files, the output files are written to a separate folder for each constituent. Most important are the five summary files, each of which covers all the sites for that consituent. These are prefixed with the constituent name, so for NO3, these are:

```
- output
  - NO3
    - NO3_inputs.csv       # input data summary
    - NO3_annual.csv       # annual predicted loads from each model
    - NO3_multiYear.csv    # multiyear predicted loads from each model
    - NO3_modelMetrics.csv # diagnostics and descriptive metrics for each model
    - NO3_plots.pdf        # plots of input data, predicted loads, and model diagnostics
```
      
Additionally, there are four folders containing individual .csv files for each site. The four .csv files listed above summarize the contents of those folders.

## Conventions to remember

* Column names and metadata slots for site information are assumed to refer to the water quality site, unless the name specifies they refer to discharge.

* IDs for constituents, discharge, and sites need to be consistent across the User Inputs section of `batch.R`, the `siteInfo` file, and the folder and file names in the `siteInputs` folder.

